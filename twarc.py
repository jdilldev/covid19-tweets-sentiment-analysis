# -*- coding: utf-8 -*-
"""twarc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PfPIbaQDx_36hJgJKXmAM6WOaQBrka1R
"""

# import the libraries
import scipy.stats as st
from collections import Counter
from textblob import TextBlob
from textblob.sentiments import NaiveBayesAnalyzer
from nltk.sentiment import SentimentIntensityAnalyzer
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
import plotly.graph_objects as go
import plotly.express as px
from textblob import Blobber
from textblob.sentiments import NaiveBayesAnalyzer
tb = Blobber(analyzer=NaiveBayesAnalyzer())
sia = SentimentIntensityAnalyzer()

print('beginning processing')
"""# Your bearer token here
twitter = Twarc2(bearer_token=bearerToken, metadata=False)

# Search query on various hashtags related to the pandemic, tweet must have a location and be in English and cannot be a retweet
twitter_query="(#covid OR #Covid OR #covid-19 OR #Covid-19 OR #covid19 OR #Covid19 OR #COVID OR #covid OR #Coronavirus OR #coronavirus) has:geo lang:en place_country:US -is:retweet"

# Pre-pandemic start and end datetimes
pre_pandemic_search_start = datetime.datetime(2020, 3, 11, 0, 0, 0, 1, datetime.timezone.utc)
pre_pandemic_search_end = datetime.datetime(2020, 7, 21, 11, 59, 59, 59, datetime.timezone.utc)

# Post-pandemic start and end datetimes
post_pandemic_search_start = datetime.datetime(2020, 12, 18, 0, 0, 0, 1, datetime.timezone.utc)
post_pandemic_search_end = datetime.datetime(2021, 4, 30, 11, 59, 59, 59, datetime.timezone.utc)

pre_pandemic_search = twitter.search_all(query=twitter_query, max_results=500,start_time=pre_pandemic_search_start,end_time=pre_pandemic_search_end)

post_pandemic_search = twitter.search_all(query=twitter_query, max_results=500,start_time=post_pandemic_search_start,end_time=post_pandemic_search_end)

#data


```
pre_pandemic_data=[]
post_pandemic_data=[]
  ```

# Get all pre-pandemic results page by page:
for page in pre_pandemic_search:
    pre_pandemic_data=pre_pandemic_data+flatten(page)
    print(len(pre_pandemic_data),' tweets for pre-pandemic received')

    #continue processing until 2.5 million tweets have been received
    if (len(pre_pandemic_data) <25000000):
      continue
    else:
      break

# Get all post-pandemic results page by page:


```
for page in post_pandemic_search:
    post_pandemic_data=post_pandemic_data+flatten(page)
    print(len(post_pandemic_data),' tweets for post-pandemic received')

    #continue processing until 2.5 million tweets have been received
    if (len(post_pandemic_data) <25000000):
      continue
    else:
      break
```
"""

print('reading pre vaccine CSV')
preCovid_df= pd.read_csv('./final-pre.csv', usecols=["created_at", "text", "geo.full_name", 'author.location'])
print('reading post vaccine CSV')
postCovid_df= pd.read_csv('./final-post.csv', usecols=["created_at", "text", "geo.full_name",'author.location'])

preCovid_df.columns=['Created Date','Tweet','Tweet Location','User Location']
postCovid_df.columns=['Created Date','Tweet','Tweet Location','User Location']

print(type(preCovid_df))

states = {
    'Alabama': 'AL',
    'Alaska': 'AK',
    'Arizona': 'AZ',
    'Arkansas': 'AR',
    'California': 'CA',
    'Colorado': 'CO',
    'Connecticut': 'CT',
    'Delaware': 'DE',
    'District Of Columbia': 'DC',
    'Florida': 'FL',
    'Georgia': 'GA',
    'Hawaii': 'HI',
    'Idaho': 'ID',
    'Illinois': 'IL',
    'Indiana': 'IN',
    'Iowa': 'IA',
    'Kansas': 'KS',
    'Kentucky': 'KY',
    'Louisiana': 'LA',
    'Maine': 'ME',
    'Maryland': 'MD',
    'Massachusetts': 'MA',
    'Michigan': 'MI',
    'Minnesota': 'MN',
    'Mississippi': 'MS',
    'Missouri': 'MO',
    'Montana': 'MT',
    'Nebraska': 'NE',
    'Nevada': 'NV',
    'New Hampshire': 'NH',
    'New Jersey': 'NJ',
    'New Mexico': 'NM',
    'New York': 'NY',
    'North Carolina': 'NC',
    'North Dakota': 'ND',
    'Ohio': 'OH',
    'Oklahoma': 'OK',
    'Oregon': 'OR',
    'Pennsylvania': 'PA',
    'Rhode Island': 'RI',
    'South Carolina': 'SC',
    'South Dakota': 'SD',
    'Tennessee': 'TN',
    'Texas': 'TX',
    'Utah': 'UT',
    'Vermont': 'VT',
    'Virgin Islands': 'VI',
    'Virginia': 'VA',
    'Washington': 'WA',
    'West Virginia': 'WV',
    'Wisconsin': 'WI',
    'Wyoming': 'WY',
}


def retrieve_location(location):
    if ("," in location):
        location_set= set(i.lower().strip().replace(',','') for i in location.split())
        state_abbrv_set = set(i.lower() for i in states.values())
        state_name_set = set(i.lower() for i in states.keys())

        if (len(state_abbrv_set&location_set)==0):
            if (len(state_abbrv_set&location_set)==0):
                if (len(state_name_set&location_set)==1):
                    return states.get(list(state_name_set&location_set)[0].title().strip())
                else:
                    location_set_2 = set(i.lower().strip() for i in location.split(','))
                    if (len(location_set_2&state_name_set)==1):
                        return states.get(list(state_name_set&location_set_2)[0].title().strip())
                    elif (len(location_set_2&state_abbrv_set)==1):
                        return list(state_abbrv_set&location_set_2)[0].upper().strip()
                    else:
                        return 'Unknown'
        else:
            return (location.split(',')[-1]).upper().strip()
    elif (location in states.keys()):
        return states.get(location)
    elif (location in states.values()):
        return location.strip()
    else:
        return 'Unknown'

def extract_place_helper(location):
    if ("," in location):
        return True
    elif (location in states.keys()):
        return True
    elif (location in states.values()):
        return True
    else:
        return False

#Store the tweets for pre; full-text returned by default
def extract_place(tweet_location, user_location):
    if (isinstance(tweet_location, str)):
        if (extract_place_helper(tweet_location)):
            return retrieve_location(tweet_location)
        elif (isinstance(user_location, str)):
            if (extract_place_helper(user_location)):
                return retrieve_location(user_location)
            else: return 'Unknown'
        else:
            return 'Unknown'
    elif (isinstance(user_location, str)):
        if (extract_place_helper(user_location)):
            return retrieve_location(user_location)
        else:
            return 'Unknown'
    else:
        return 'Unknown'

preCovid_df['Location'] = preCovid_df.apply(lambda x: extract_place(x['Tweet Location'], x['User Location']), axis=1)
postCovid_df['Location'] = postCovid_df.apply(lambda x: extract_place(x['Tweet Location'], x['User Location']), axis=1)

print('finished applying locations to tweets')
#preCovid_df.head(60)

#postCovid_df.head(60)

def deEmojify(text):
    return re.sub(r'[^\w\s,]','',text)

#Create a function to clean the tweets
#Create a function to clean the tweets
def cleanTwt(twt):
   if(isinstance(twt, str)):
     twt = re.sub('#Covid', 'Covid', twt) # Removes the '#' from covid19
     twt = re.sub('#COVID', 'COVID', twt) # Removes the '#' from covid19
     twt = re.sub('#covid', 'covid', twt) # Removes the '#' from covid19
     twt = re.sub('#covid19', 'covid19', twt) # Removes the '#' from covid19
     twt = re.sub('#Covid19', 'Covid19', twt) # Removes the '#' from Covid19
     twt = re.sub('#Covid-19', 'Covid-19', twt) # Removes the '#' from Covid19
     twt = re.sub('#covid19', 'covid-19', twt) # Removes the '#' from Covid19
     twt = re.sub('#Coronavirus', 'Coronavirus', twt) # Removes the '#' from Covid19
     twt = re.sub('#coronavirus', 'coronavirus', twt) # Removes the '#' from Covid19
     twt = re.sub('#[A-Za-z0-9]+', '', twt) #Removes any string with a '#'
     twt = re.sub('\\n', '', twt) #Removes the '\n' string
     twt = re.sub('https?:\/\/\S+', '', twt) #Removes any hyperlinks
     return deEmojify(twt)
   else:
      print(twt)
      return ""

#Clean the tweets

preCovid_df['Cleaned_Tweet'] = preCovid_df['Tweet'].apply(lambda x:cleanTwt(x))
postCovid_df['Cleaned_Tweet'] = postCovid_df['Tweet'].apply(lambda x:cleanTwt(x))
print('finished cleaning tweets')

#Create a function to get the subjectivity
def getSubjectivity(twt):
    return TextBlob(twt).sentiment.subjectivity
#Create a function to get the polarity
def getPolarity(twt):
    blob_object = TextBlob(twt, analyzer=NaiveBayesAnalyzer())
    return blob_object.polarity

#Create a function to get the polarity
def getPolarityTwo(twt):
    return sia.polarity_scores(twt)['compound']

#Create two new columns called 'Subjectivity' & 'Polarity
print('getting polarity of pre-covid')
preCovid_df['Polarity'] = preCovid_df['Cleaned_Tweet'].apply(getPolarityTwo)
print('getting subjectivity of pre-covid')
preCovid_df['Subjectivity'] = preCovid_df['Cleaned_Tweet'].apply(getSubjectivity)

#preCovid_df['Polarity'] = preCovid_df['Cleaned_Tweet'].apply(getPolarity)

print('getting subjectivity of post-covid')
postCovid_df['Subjectivity'] = postCovid_df['Cleaned_Tweet'].apply(getSubjectivity)
print('getting polarity of post-covid')
#postCovid_df['Polarity'] = postCovid_df['Cleaned_Tweet'].apply(getPolarity)
postCovid_df['Polarity'] = postCovid_df['Cleaned_Tweet'].apply(getPolarityTwo)

print('finished getting subjectivity and polarity')

#Show the data
preCovid_df.head(5)

#Create a function to get the  text sentiment
def getSentiment(score):
    if score < 0:
        return 'Negative'
    elif score == 0:
        return 'Neutral'
    else:
        return 'Positive'

#Create a column to store the text sentiment
preCovid_df['Sentiment'] = preCovid_df['Polarity'].apply(getSentiment)
postCovid_df['Sentiment'] = postCovid_df['Polarity'].apply(getSentiment)

print('finished getting sentiment')

#Show the data
preCovid_df.head(5)

#Show the data
postCovid_df.head(5)

#Create a scatterplot to show the subjectivity and polarity
print('building scatter plot')

df1 = pd.DataFrame({'Polarity':preCovid_df['Polarity'],'Subjectivity':preCovid_df['Subjectivity'], 'Phase':'Before Vaccine'})
df2 = pd.DataFrame({'Polarity':postCovid_df['Polarity'],'Subjectivity':postCovid_df['Subjectivity'], 'Phase':'After Vaccine'})

frames = [df1, df2]
result = pd.concat(frames)

fig = px.scatter(result, x="Polarity", y="Subjectivity", color="Phase",hover_data=['Polarity','Subjectivity','Phase'],opacity=0.2,color_discrete_sequence=['lightseagreen','purple'],range_color=(0,1) )
fig.update_layout(xaxis_range=[-1,1])
fig.update_layout(paper_bgcolor='lightgray', plot_bgcolor='lightgray')

fig.show()

#Create a bar chart to show the count of Positive, Neutral, and Negative Sentiments
sentiment=['Positive', 'Negative', 'Neutral']
print('building bar chart')

fig = go.Figure()
fig.add_trace(go.Bar(x=sentiment,
                y=[len(preCovid_df[preCovid_df['Sentiment'] == 'Positive']),len(preCovid_df[preCovid_df['Sentiment'] == 'Negative']),len(preCovid_df[preCovid_df['Sentiment'] == 'Neutral'])],
                name='Pre Vaccine',
                marker_color='teal'
                ))
fig.add_trace(go.Bar(x=sentiment,
                y=[len(postCovid_df[postCovid_df['Sentiment'] == 'Positive']),len(postCovid_df[postCovid_df['Sentiment'] == 'Negative']),len(postCovid_df[postCovid_df['Sentiment'] == 'Neutral'])],
                name='Post Vaccine',
                marker_color='steelblue'
                ))

fig.update_layout(
    title='Number of Tweets per Sentiment',
    xaxis_tickfont_size=14,
    yaxis=dict(
        title='Tweet Count (millions)',
        titlefont_size=16,
        tickfont_size=14,
    ),
    xaxis=dict(
        title='Sentiment',
        titlefont_size=16,
        tickfont_size=14,
    ),
    paper_bgcolor='lightgray',
    plot_bgcolor='lightgray',
    barmode='group',
    bargap=0.15, # gap between bars of adjacent location coordinates.
    bargroupgap=0.1 # gap between bars of the same location coordinate.
)

fig.show()

print('getting stats')

print('Sentiment Percentages Pre-Vaccine')
print('Positive: ',len(preCovid_df[preCovid_df['Sentiment'] == 'Positive'])/len(preCovid_df['Sentiment'].index)*100)
print('Negative: ',len(preCovid_df[preCovid_df['Sentiment'] == 'Negative'])/len(preCovid_df['Sentiment'].index)*100)
print('Neutral: ',len(preCovid_df[preCovid_df['Sentiment'] == 'Neutral'])/len(preCovid_df['Sentiment'].index)*100,'\n')

print('Sentiment Percentages Post-Vaccine')
print('Positive: ',len(postCovid_df[postCovid_df['Sentiment'] == 'Positive'])/len(postCovid_df['Sentiment'].index)*100)
print('Negative: ',len(postCovid_df[postCovid_df['Sentiment'] == 'Negative'])/len(postCovid_df['Sentiment'].index)*100)
print('Neutral: ',len(postCovid_df[postCovid_df['Sentiment'] == 'Neutral'])/len(postCovid_df['Sentiment'].index)*100,'\n')

print('Polarity Means')
print('Before: ',np.mean(preCovid_df['Polarity']))
print('After: ',np.mean(postCovid_df['Polarity']))

print('Polarity Standard Deviation')
print('Before: ',np.std(preCovid_df['Polarity']))
print('After: ',np.std(postCovid_df['Polarity']))

print('Polarity Confidence Intervals')
print('Before: ',st.t.interval(alpha=0.95, df=len(preCovid_df['Polarity'])-1, loc=np.mean(preCovid_df['Polarity']), scale=st.sem(preCovid_df['Polarity'])))
print('After: ',st.t.interval(alpha=0.95, df=len(postCovid_df['Polarity'])-1, loc=np.mean(postCovid_df['Polarity']), scale=st.sem(postCovid_df['Polarity'])))


print('Subjectivity Means')
print('Before: ',np.mean(preCovid_df['Subjectivity']))
print('After: ',np.mean(postCovid_df['Subjectivity']))

print('Subjectivity Standard Deviation')
print('Before',np.std(preCovid_df['Subjectivity']))
print('After',np.std(postCovid_df['Subjectivity']))

print('Subjectivity Confidence Intervals')
print('Before: ',st.t.interval(alpha=0.95, df=len(preCovid_df['Subjectivity'])-1, loc=np.mean(preCovid_df['Subjectivity']), scale=st.sem(preCovid_df['Subjectivity'])))
print('After: ',st.t.interval(alpha=0.95, df=len(postCovid_df['Subjectivity'])-1, loc=np.mean(postCovid_df['Subjectivity']), scale=st.sem(postCovid_df['Subjectivity'])))



preCovid_df.Location = [x.strip() for x in preCovid_df.Location]
postCovid_df.Location = [x.strip() for x in postCovid_df.Location]

#Pass in CSV listing tweet count per state
state_data_df = pd.DataFrame(columns=['State','Overall Sentiment Before Vaccine','Number of Tweets Before Vaccine','Mean Polarity Before Vaccine','Mean Subjectivity Before Vaccine','Number of Tweets After Vaccine','Overall Sentiment After Vaccine','Mean Polarity After Vaccine', 'Mean Subjectivity After Vaccine'])


for index, state in enumerate(states.values()):
    c_pre = Counter(preCovid_df[preCovid_df['Location'] == state]['Sentiment'])
    c_post = Counter(postCovid_df[postCovid_df['Location'] == state]['Sentiment'])
    state_data_df.loc[index, 'State'] = state
    if (c_pre.most_common(1)):
        state_data_df.loc[index, 'Overall Sentiment Before Vaccine'] = c_pre.most_common(1)[0][0]
    else:
        state_data_df.loc[index, 'Overall Sentiment Before Vaccine'] ='Empty'
    if (c_post.most_common(1)):
        state_data_df.loc[index, 'Overall Sentiment After Vaccine'] = c_post.most_common(1)[0][0]
    else:
        state_data_df.loc[index, 'Overall Sentiment After Vaccine'] ='Empty'
    if (c_pre.most_common(1) and c_post.most_common(1)):
        state_data_df.loc[index, 'Sentiment Change'] = 'No' if c_post.most_common(1)[0][0]==c_pre.most_common(1)[0][0] else 'Yes'
    else:
        state_data_df.loc[index, 'Sentiment Change'] = 'Empty'
    state_data_df.loc[index, 'Number of Tweets Before Vaccine'] =  len(preCovid_df[preCovid_df['Location'] == state])
    state_data_df.loc[index, 'Number of Tweets After Vaccine'] =  len(postCovid_df[postCovid_df['Location'] == state])
    state_data_df.loc[index, 'Mean Polarity Before Vaccine'] = 0.0
    state_data_df.loc[index, 'Mean Polarity After Vaccine'] = 0.0
    state_data_df.loc[index, 'Mean Subjectivity Before Vaccine'] = 0.0
    state_data_df.loc[index, 'Mean Subjectivity After Vaccine'] = 0.0



for index, state in enumerate(state_data_df['State']):
    if(preCovid_df.loc[preCovid_df['Location'] == state]['Polarity'].values.size > 0):
        state_data_df.loc[index, 'Mean Polarity Before Vaccine'] = np.mean(preCovid_df.loc[preCovid_df['Location'] == state]['Polarity'].values)
        state_data_df.loc[index, 'Mean Subjectivity Before Vaccine'] = np.mean(preCovid_df.loc[preCovid_df['Location'] == state]['Subjectivity'].values)


    if(postCovid_df.loc[postCovid_df['Location'] == state]['Polarity'].values.size > 0):
        state_data_df.loc[index, 'Mean Polarity After Vaccine'] = np.mean(postCovid_df.loc[postCovid_df['Location'] == state]['Polarity'].values)
        state_data_df.loc[index, 'Mean Subjectivity After Vaccine'] = np.mean(postCovid_df.loc[postCovid_df['Location'] == state]['Subjectivity'].values)



print('Number of Tweets in which the state could not be determined, Before Vaccine: ',len(preCovid_df[preCovid_df['Location'] == 'Unknown']))
print('building num tweets choropleth')

fig = go.Figure(data=go.Choropleth(
    locations=state_data_df['State'], # Spatial coordinates
    z = state_data_df ['Number of Tweets Before Vaccine'].astype(int), # Data to be color-coded
    locationmode = 'USA-states', # set of locations match entries in `locations`
    colorscale = 'Mint',
    colorbar_title = "Number of Tweets",
))


fig.update_layout(
    title_text = 'Tweet Count by State Before Vaccine',
    geo_scope='usa', # limit map scope to USA
)

fig.show()

print('Number of Tweets in which the state could not be determined, After Vaccine: ',len(postCovid_df[postCovid_df['Location'] == 'Unknown']))

fig2 = go.Figure(data=go.Choropleth(
    locations=state_data_df ['State'], # Spatial coordinates
    z = state_data_df ['Number of Tweets After Vaccine'].astype(int), # Data to be color-coded
    locationmode = 'USA-states', # set of locations match entries in `locations`
    colorscale = 'Mint',
    colorbar_title = "Number of Tweets",
))

fig2.update_layout(
    title_text = 'Tweet Count by State After Vaccine',
    geo_scope='usa', # limit map scope to USA
)

fig2.show()

print('building subjectivity choropleths')

fig = go.Figure(data=go.Choropleth(
    locations=state_data_df['State'], # Spatial coordinates
    z = state_data_df ['Mean Subjectivity Before Vaccine'].astype(float), # Data to be color-coded
    locationmode = 'USA-states', # set of locations match entries in `locations`
    colorscale='Magenta',
    colorbar_title = "Average Subjectivity",
))

fig.update_layout(
    title_text = 'Mean Subjectivity per State Before Vaccine',
    geo_scope='usa', # limit map scope to USA
)

fig.show()

fig2 = go.Figure(data=go.Choropleth(
    locations=state_data_df ['State'], # Spatial coordinates
    z = state_data_df ['Mean Subjectivity After Vaccine'].astype(float), # Data to be color-coded
    locationmode = 'USA-states', # set of locations match entries in `locations`
    colorscale = 'Magenta',
    colorbar_title = "Average Subjectivity",
))

fig2.update_layout(
    title_text = 'Mean Subjectivity per State After Vaccine',
    geo_scope='usa', # limit map scope to USA
)

fig2.show()

print('building polarity choropleths')

fig = go.Figure(data=go.Choropleth(
    locations=state_data_df['State'], # Spatial coordinates
    z = state_data_df['Mean Polarity Before Vaccine'].astype(float), # Data to be color-coded
    locationmode = 'USA-states', # set of locations match entries in `locations`
    colorscale = 'Purp',
    colorbar_title = "Average Polarity",
    text=state_data_df.apply(lambda row: f"Average Polarity: {row['Mean Polarity Before Vaccine']}<br>State:{row['State']}", axis=1),
    hoverinfo="text"
    #colorbar=dict(tickvals=[-.06,.0, .131], ticktext=['-1','0', '1'], outlinewidth=0),
)
)

fig.update_layout(
    title_text = 'Mean Polarity per State Before Vaccine',
    geo_scope='usa', # limit map scope to USA
)

fig.show()

fig2 = go.Figure(data=go.Choropleth(
    locations=state_data_df ['State'], # Spatial coordinates
    z = state_data_df ['Mean Polarity After Vaccine'].astype(float), # Data to be color-coded
    locationmode = 'USA-states', # set of locations match entries in `locations`
    colorscale='Purp',
    colorbar_title = "Average Polarity",
    #colorbar=dict(tickvals=[-.01,0, .131], ticktext=['-1','0', '1'], outlinewidth=0),
))

fig2.update_layout(
    title_text = 'Mean Polarity per State After Vaccine',
    geo_scope='usa', # limit map scope to USA,
)

fig2.show()

print('building overall sentiment choropleths')


colors = px.colors.sequential.YlGnBu

fig =px.choropleth(state_data_df,
                   locations='State',
                   locationmode='USA-states',
                   scope='usa',
                   color='Overall Sentiment Before Vaccine',
                   color_discrete_map=dict(zip(state_data_df['Overall Sentiment Before Vaccine'].unique(), colors))

                   )

fig.show()

fig =px.choropleth(state_data_df,
                   locations='State',
                   locationmode='USA-states',
                   scope='usa',
                   color='Overall Sentiment After Vaccine',
                   color_discrete_map=dict(zip(state_data_df['Overall Sentiment After Vaccine'].unique(), colors))

                   )

fig.show()
#Save dataframes to CSV files
print('saving data to CSVs')
#stats_df.to_csv('./stats.csv')
state_data_df.to_csv('./map-data.csv')

preCovid_df.to_html('./final-pre-covid.html')
postCovid_df.to_html('./final-post-covid.html')

print('ending processing')
